{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import sklearn.feature_selection as skfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To normalize data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#To encode\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "#Split data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "#For KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education  education-num      marital-status  \\\n",
       "0   39         State-gov  Bachelors             13       Never-married   \n",
       "1   50  Self-emp-not-inc  Bachelors             13  Married-civ-spouse   \n",
       "2   38           Private    HS-grad              9            Divorced   \n",
       "\n",
       "          occupation   relationship   race   sex  capital-gain  capital-loss  \\\n",
       "0       Adm-clerical  Not-in-family  White  Male          2174             0   \n",
       "1    Exec-managerial        Husband  White  Male             0             0   \n",
       "2  Handlers-cleaners  Not-in-family  White  Male             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              13  United-States  <=50K  \n",
       "2              40  United-States  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define column names\n",
    "names = ['age', 'workclass', 'education', 'education-num', 'marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','income']\n",
    "\n",
    "# loading training data (df = data frame)\n",
    "df = pd.read_csv(r\"C:\\Users\\Madhushi\\Desktop\\ML1_Assignment\\Adult_Census_Income_Binary_Classification_dataset.csv\", header=0, names=names, sep=',\\s+', delimiter=',', encoding=\"utf-8\", skipinitialspace=True)\n",
    "\n",
    "#display first 3 rows of the data frame\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1836\n",
       "education            0\n",
       "education-num        0\n",
       "marital-status       0\n",
       "occupation        1843\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital-gain         0\n",
       "capital-loss         0\n",
       "hours-per-week       0\n",
       "native-country     583\n",
       "income               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre processing 1 - Removing missing values start\n",
    "\n",
    "#number of missing values in each column\n",
    "(df[['age', 'workclass', 'education', 'education-num', 'marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','income']] == \"?\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark ? values as missing or NaN\n",
    "df[['workclass', 'occupation','native-country']] = df[['workclass', 'occupation','native-country']].replace('?', np.NaN)\n",
    "\n",
    "# count the number of NaN values in each column\n",
    "df.isnull().sum()\n",
    "\n",
    "# drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#removing missing values end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_binned</th>\n",
       "      <th>education-num_binned</th>\n",
       "      <th>capital-gain_binned</th>\n",
       "      <th>capital-loss_binned</th>\n",
       "      <th>hours-per-week_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education  education-num      marital-status  \\\n",
       "0   39         State-gov  Bachelors             13       Never-married   \n",
       "1   50  Self-emp-not-inc  Bachelors             13  Married-civ-spouse   \n",
       "2   38           Private    HS-grad              9            Divorced   \n",
       "3   53           Private       11th              7  Married-civ-spouse   \n",
       "4   28           Private  Bachelors             13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital-gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1    Exec-managerial        Husband  White    Male             0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3  Handlers-cleaners        Husband  Black    Male             0   \n",
       "4     Prof-specialty           Wife  Black  Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week native-country income age_binned  \\\n",
       "0             0              40  United-States  <=50K          3   \n",
       "1             0              13  United-States  <=50K          4   \n",
       "2             0              40  United-States  <=50K          3   \n",
       "3             0              40  United-States  <=50K          5   \n",
       "4             0              40           Cuba  <=50K          2   \n",
       "\n",
       "  education-num_binned capital-gain_binned capital-loss_binned  \\\n",
       "0                    2                   1                   0   \n",
       "1                    2                   0                   0   \n",
       "2                    1                   0                   0   \n",
       "3                    1                   0                   0   \n",
       "4                    2                   0                   0   \n",
       "\n",
       "  hours-per-week_binned  \n",
       "0                     3  \n",
       "1                     1  \n",
       "2                     3  \n",
       "3                     3  \n",
       "4                     3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre processing 2 - Binning Start(Continuous variables)\n",
    "\n",
    "#Bin Age\n",
    "bins = [0,10,20,30,40,50,60,70,80,90,100]\n",
    "labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "df['age_binned'] = pd.cut(df['age'], bins=bins, labels=labels)\n",
    "#df.assign(age_binned=df.groupby(pd.cut(df['age'], bins=bins, labels=labels))['age'].transform('age_binned'))\n",
    "\n",
    "#Bin education number\n",
    "bins = [0,5,10,15,20]\n",
    "labels = [0,1,2,3]\n",
    "df['education-num_binned'] = pd.cut(df['education-num'], bins=bins, labels=labels)\n",
    "\n",
    "#Bin capital gain\n",
    "#Those who have a capital gain will be marked as 1\n",
    "bins = [-1,1,1000000]\n",
    "labels = [0,1]\n",
    "df['capital-gain_binned'] = pd.cut(df['capital-gain'], bins=bins, labels=labels)\n",
    "\n",
    "#Bin capital loss\n",
    "#Those who have a capital loss will be marked as 1\n",
    "bins = [-1,1,1000000]\n",
    "labels = [0,1]\n",
    "df['capital-loss_binned'] = pd.cut(df['capital-loss'], bins=bins, labels=labels)\n",
    "\n",
    "#Bin hours per week\n",
    "bins = [0,10,20,30,40,50,60,70,80,90,100]\n",
    "labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "df['hours-per-week_binned'] = pd.cut(df['hours-per-week'], bins=bins, labels=labels)\n",
    "\n",
    "#Binning end\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>age_binned</th>\n",
       "      <th>education-num_binned</th>\n",
       "      <th>capital-gain_binned</th>\n",
       "      <th>capital-loss_binned</th>\n",
       "      <th>hours-per-week_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  education  education-num  marital-status  occupation  \\\n",
       "0   39          5          9             13               4           0   \n",
       "1   50          4          9             13               2           3   \n",
       "2   38          2         11              9               0           5   \n",
       "\n",
       "   relationship  race  sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0             1     4    1          2174             0              40   \n",
       "1             0     4    1             0             0              13   \n",
       "2             1     4    1             0             0              40   \n",
       "\n",
       "   native-country  income age_binned education-num_binned capital-gain_binned  \\\n",
       "0              38       0          3                    2                   1   \n",
       "1              38       0          4                    2                   0   \n",
       "2              38       0          3                    1                   0   \n",
       "\n",
       "  capital-loss_binned hours-per-week_binned  \n",
       "0                   0                     3  \n",
       "1                   0                     1  \n",
       "2                   0                     3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre processinng 3 - Encoding Categorical Data\n",
    "\n",
    "le=LabelEncoder()\n",
    "# Iterating over all the common columns in train and test\n",
    "for col in names:\n",
    "       #Encoding only categorical variables\n",
    "       if df[col].dtypes == 'object':\n",
    "        #Using whole data to form an exhaustive list of levels\n",
    "           le.fit(df[col].values)\n",
    "           df[col]=le.transform(df[col])\n",
    "            \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing into training and testing datasets start\n",
    "\n",
    "# create design matrix X and target vector y\n",
    "#X = np.array(df.loc['workclass', 'education', 'marital-status','occupation','relationship','race','sex','capital-gain','capital-loss', 'native-country', 'education-num_binned', 'age_binned', 'hours-per-week_binned'])\n",
    "#y = np.array(df['income'])\n",
    "\n",
    "y = df.income\n",
    "X = df.drop(['income', 'age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], axis=1)\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) #, random_state=42\n",
    "\n",
    "#Dividing into training and testing datasets end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing 4 - Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Order of importance\n",
    "#occupation, relationship, age_binned, marital-status, hours-per-week_binned, education-num_binned, education, capital-gain_binned, workclass, sex, native-country, capital-loss_binned, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "      <th>age_binned</th>\n",
       "      <th>education-num_binned</th>\n",
       "      <th>capital-gain_binned</th>\n",
       "      <th>capital-loss_binned</th>\n",
       "      <th>hours-per-week_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   workclass  education  marital-status  occupation  relationship  race  sex  \\\n",
       "0          5          9               4           0             1     4    1   \n",
       "\n",
       "   native-country age_binned education-num_binned capital-gain_binned  \\\n",
       "0              38          3                    2                   1   \n",
       "\n",
       "  capital-loss_binned hours-per-week_binned  \n",
       "0                   0                     3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8206431649906067\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "#KNN algorithm Using Python `sklearn' package start\n",
    "\n",
    "#Instatiating Training and evaluating the model start\n",
    "\n",
    "# instantiate learning model (k = 5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict the response\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "# evaluate accuracy\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the optimal k start\n",
    "\n",
    "# creating odd list of K for KNN\n",
    "myList = list(range(1,20))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = list(filter(lambda x: x % 2 != 0, myList))\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is 15\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x221b9a61e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()\n",
    "\n",
    "#Finding the optimal k end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.829373411426677\n"
     ]
    }
   ],
   "source": [
    "#Re-evaluating with the optimal k start\n",
    "\n",
    "# instantiate learning model (k = 15)\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict the response\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "# evaluate accuracy\n",
    "print(accuracy_score(y_test, pred))\n",
    "\n",
    "#Re-evaluating with the optimal k end\n",
    "\n",
    "#KNN algorithm Using Python `sklearn' package end\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21113 samples, validate on 9049 samples\n",
      "Epoch 1/300\n",
      "21113/21113 [==============================] - 410s 19ms/step - loss: 1.2459 - val_loss: 0.6868\n",
      "Epoch 2/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.5786 - val_loss: 0.4981\n",
      "Epoch 3/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4869 - val_loss: 0.4580\n",
      "Epoch 4/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4624 - val_loss: 0.4434\n",
      "Epoch 5/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4520 - val_loss: 0.4374\n",
      "Epoch 6/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4467 - val_loss: 0.4364\n",
      "Epoch 7/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4434 - val_loss: 0.4299\n",
      "Epoch 8/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4419 - val_loss: 0.4328\n",
      "Epoch 9/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4409 - val_loss: 0.4295\n",
      "Epoch 10/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4393 - val_loss: 0.4278\n",
      "Epoch 11/300\n",
      "21113/21113 [==============================] - 1s 39us/step - loss: 0.4385 - val_loss: 0.4248\n",
      "Epoch 12/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4379 - val_loss: 0.4262\n",
      "Epoch 13/300\n",
      "21113/21113 [==============================] - 1s 52us/step - loss: 0.4374 - val_loss: 0.4250\n",
      "Epoch 14/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4366 - val_loss: 0.4244\n",
      "Epoch 15/300\n",
      "21113/21113 [==============================] - 1s 44us/step - loss: 0.4365 - val_loss: 0.4224\n",
      "Epoch 16/300\n",
      "21113/21113 [==============================] - 1s 39us/step - loss: 0.4355 - val_loss: 0.4220\n",
      "Epoch 17/300\n",
      "21113/21113 [==============================] - 1s 49us/step - loss: 0.4353 - val_loss: 0.4218\n",
      "Epoch 18/300\n",
      "21113/21113 [==============================] - 1s 43us/step - loss: 0.4344 - val_loss: 0.4216\n",
      "Epoch 19/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4344 - val_loss: 0.4224\n",
      "Epoch 20/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4337 - val_loss: 0.4230\n",
      "Epoch 21/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4333 - val_loss: 0.4202\n",
      "Epoch 22/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4329 - val_loss: 0.4189\n",
      "Epoch 23/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4324 - val_loss: 0.4198\n",
      "Epoch 24/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4319 - val_loss: 0.4185\n",
      "Epoch 25/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4316 - val_loss: 0.4190\n",
      "Epoch 26/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4313 - val_loss: 0.4174\n",
      "Epoch 27/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4308 - val_loss: 0.4172\n",
      "Epoch 28/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4304 - val_loss: 0.4177\n",
      "Epoch 29/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4300 - val_loss: 0.4210\n",
      "Epoch 30/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4298 - val_loss: 0.4229\n",
      "Epoch 31/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4294 - val_loss: 0.4163\n",
      "Epoch 32/300\n",
      "21113/21113 [==============================] - 1s 42us/step - loss: 0.4287 - val_loss: 0.4154\n",
      "Epoch 33/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4287 - val_loss: 0.4152\n",
      "Epoch 34/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4284 - val_loss: 0.4167\n",
      "Epoch 35/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4281 - val_loss: 0.4151\n",
      "Epoch 36/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4277 - val_loss: 0.4190\n",
      "Epoch 37/300\n",
      "21113/21113 [==============================] - 1s 51us/step - loss: 0.4274 - val_loss: 0.4148\n",
      "Epoch 38/300\n",
      "21113/21113 [==============================] - 1s 46us/step - loss: 0.4269 - val_loss: 0.4152\n",
      "Epoch 39/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4267 - val_loss: 0.4152\n",
      "Epoch 40/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4267 - val_loss: 0.4131\n",
      "Epoch 41/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4262 - val_loss: 0.4147\n",
      "Epoch 42/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4260 - val_loss: 0.4173\n",
      "Epoch 43/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4258 - val_loss: 0.4147\n",
      "Epoch 44/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4255 - val_loss: 0.4128\n",
      "Epoch 45/300\n",
      "21113/21113 [==============================] - 1s 41us/step - loss: 0.4254 - val_loss: 0.4140\n",
      "Epoch 46/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4252 - val_loss: 0.4131\n",
      "Epoch 47/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4249 - val_loss: 0.4125\n",
      "Epoch 48/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4243 - val_loss: 0.4119\n",
      "Epoch 49/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4245 - val_loss: 0.4120\n",
      "Epoch 50/300\n",
      "21113/21113 [==============================] - 1s 44us/step - loss: 0.4243 - val_loss: 0.4148\n",
      "Epoch 51/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4235 - val_loss: 0.4114\n",
      "Epoch 52/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4238 - val_loss: 0.4106\n",
      "Epoch 53/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4239 - val_loss: 0.4104\n",
      "Epoch 54/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4235 - val_loss: 0.4100\n",
      "Epoch 55/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4232 - val_loss: 0.4105\n",
      "Epoch 56/300\n",
      "21113/21113 [==============================] - 1s 46us/step - loss: 0.4231 - val_loss: 0.4119\n",
      "Epoch 57/300\n",
      "21113/21113 [==============================] - 1s 54us/step - loss: 0.4229 - val_loss: 0.4112\n",
      "Epoch 58/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4226 - val_loss: 0.4096\n",
      "Epoch 59/300\n",
      "21113/21113 [==============================] - 1s 39us/step - loss: 0.4225 - val_loss: 0.4109\n",
      "Epoch 60/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4220 - val_loss: 0.4139\n",
      "Epoch 61/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4220 - val_loss: 0.4093\n",
      "Epoch 62/300\n",
      "21113/21113 [==============================] - 1s 39us/step - loss: 0.4220 - val_loss: 0.4149\n",
      "Epoch 63/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4216 - val_loss: 0.4095\n",
      "Epoch 64/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4213 - val_loss: 0.4102\n",
      "Epoch 65/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4216 - val_loss: 0.4105\n",
      "Epoch 66/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4211 - val_loss: 0.4087\n",
      "Epoch 67/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4213 - val_loss: 0.4083\n",
      "Epoch 68/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4211 - val_loss: 0.4084\n",
      "Epoch 69/300\n",
      "21113/21113 [==============================] - 1s 39us/step - loss: 0.4211 - val_loss: 0.4141\n",
      "Epoch 70/300\n",
      "21113/21113 [==============================] - 1s 44us/step - loss: 0.4209 - val_loss: 0.4096\n",
      "Epoch 71/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4207 - val_loss: 0.4088\n",
      "Epoch 72/300\n",
      "21113/21113 [==============================] - 1s 39us/step - loss: 0.4206 - val_loss: 0.4079\n",
      "Epoch 73/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4204 - val_loss: 0.4085\n",
      "Epoch 74/300\n",
      "21113/21113 [==============================] - 1s 39us/step - loss: 0.4202 - val_loss: 0.4159\n",
      "Epoch 75/300\n",
      "21113/21113 [==============================] - 1s 50us/step - loss: 0.4200 - val_loss: 0.4099\n",
      "Epoch 76/300\n",
      "21113/21113 [==============================] - 1s 52us/step - loss: 0.4199 - val_loss: 0.4202\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4201 - val_loss: 0.4091\n",
      "Epoch 78/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4197 - val_loss: 0.4079\n",
      "Epoch 79/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4196 - val_loss: 0.4150\n",
      "Epoch 80/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4196 - val_loss: 0.4070\n",
      "Epoch 81/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4196 - val_loss: 0.4075\n",
      "Epoch 82/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4190 - val_loss: 0.4169\n",
      "Epoch 83/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4193 - val_loss: 0.4070\n",
      "Epoch 84/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4191 - val_loss: 0.4075\n",
      "Epoch 85/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4192 - val_loss: 0.4062\n",
      "Epoch 86/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4190 - val_loss: 0.4085\n",
      "Epoch 87/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4191 - val_loss: 0.4059\n",
      "Epoch 88/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4189 - val_loss: 0.4057\n",
      "Epoch 89/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4188 - val_loss: 0.4060\n",
      "Epoch 90/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4184 - val_loss: 0.4060\n",
      "Epoch 91/300\n",
      "21113/21113 [==============================] - 1s 50us/step - loss: 0.4185 - val_loss: 0.4099\n",
      "Epoch 92/300\n",
      "21113/21113 [==============================] - 1s 46us/step - loss: 0.4184 - val_loss: 0.4060\n",
      "Epoch 93/300\n",
      "21113/21113 [==============================] - 1s 45us/step - loss: 0.4183 - val_loss: 0.4098\n",
      "Epoch 94/300\n",
      "21113/21113 [==============================] - 1s 41us/step - loss: 0.4183 - val_loss: 0.4054\n",
      "Epoch 95/300\n",
      "21113/21113 [==============================] - 1s 52us/step - loss: 0.4183 - val_loss: 0.4064\n",
      "Epoch 96/300\n",
      "21113/21113 [==============================] - 1s 61us/step - loss: 0.4184 - val_loss: 0.4054\n",
      "Epoch 97/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4182 - val_loss: 0.4061\n",
      "Epoch 98/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4183 - val_loss: 0.4050\n",
      "Epoch 99/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4179 - val_loss: 0.4069\n",
      "Epoch 100/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4177 - val_loss: 0.4098\n",
      "Epoch 101/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4178 - val_loss: 0.4051\n",
      "Epoch 102/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4179 - val_loss: 0.4048\n",
      "Epoch 103/300\n",
      "21113/21113 [==============================] - 1s 45us/step - loss: 0.4175 - val_loss: 0.4049\n",
      "Epoch 104/300\n",
      "21113/21113 [==============================] - 1s 49us/step - loss: 0.4177 - val_loss: 0.4061\n",
      "Epoch 105/300\n",
      "21113/21113 [==============================] - 1s 47us/step - loss: 0.4175 - val_loss: 0.4048\n",
      "Epoch 106/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4175 - val_loss: 0.4082\n",
      "Epoch 107/300\n",
      "21113/21113 [==============================] - 1s 48us/step - loss: 0.4172 - val_loss: 0.4047\n",
      "Epoch 108/300\n",
      "21113/21113 [==============================] - 1s 44us/step - loss: 0.4175 - val_loss: 0.4058\n",
      "Epoch 109/300\n",
      "21113/21113 [==============================] - 1s 49us/step - loss: 0.4174 - val_loss: 0.4044\n",
      "Epoch 110/300\n",
      "21113/21113 [==============================] - 1s 50us/step - loss: 0.4173 - val_loss: 0.4044\n",
      "Epoch 111/300\n",
      "21113/21113 [==============================] - 1s 45us/step - loss: 0.4175 - val_loss: 0.4058\n",
      "Epoch 112/300\n",
      "21113/21113 [==============================] - 1s 50us/step - loss: 0.4172 - val_loss: 0.4068\n",
      "Epoch 113/300\n",
      "21113/21113 [==============================] - 1s 47us/step - loss: 0.4173 - val_loss: 0.4051\n",
      "Epoch 114/300\n",
      "21113/21113 [==============================] - 1s 49us/step - loss: 0.4171 - val_loss: 0.4082\n",
      "Epoch 115/300\n",
      "21113/21113 [==============================] - 1s 54us/step - loss: 0.4169 - val_loss: 0.4091\n",
      "Epoch 116/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4169 - val_loss: 0.4046\n",
      "Epoch 117/300\n",
      "21113/21113 [==============================] - 1s 45us/step - loss: 0.4173 - val_loss: 0.4052\n",
      "Epoch 118/300\n",
      "21113/21113 [==============================] - 1s 47us/step - loss: 0.4170 - val_loss: 0.4044\n",
      "Epoch 119/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4167 - val_loss: 0.4058\n",
      "Epoch 120/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4168 - val_loss: 0.4043\n",
      "Epoch 121/300\n",
      "21113/21113 [==============================] - 1s 53us/step - loss: 0.4167 - val_loss: 0.4042\n",
      "Epoch 122/300\n",
      "21113/21113 [==============================] - 1s 45us/step - loss: 0.4166 - val_loss: 0.4044\n",
      "Epoch 123/300\n",
      "21113/21113 [==============================] - 1s 55us/step - loss: 0.4165 - val_loss: 0.4040\n",
      "Epoch 124/300\n",
      "21113/21113 [==============================] - 1s 47us/step - loss: 0.4166 - val_loss: 0.4104\n",
      "Epoch 125/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4168 - val_loss: 0.4063\n",
      "Epoch 126/300\n",
      "21113/21113 [==============================] - 1s 32us/step - loss: 0.4169 - val_loss: 0.4056\n",
      "Epoch 127/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4164 - val_loss: 0.4045\n",
      "Epoch 128/300\n",
      "21113/21113 [==============================] - 1s 30us/step - loss: 0.4163 - val_loss: 0.4067\n",
      "Epoch 129/300\n",
      "21113/21113 [==============================] - 1s 31us/step - loss: 0.4164 - val_loss: 0.4077\n",
      "Epoch 130/300\n",
      "21113/21113 [==============================] - 1s 39us/step - loss: 0.4165 - val_loss: 0.4038\n",
      "Epoch 131/300\n",
      "21113/21113 [==============================] - 1s 43us/step - loss: 0.4162 - val_loss: 0.4079\n",
      "Epoch 132/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4165 - val_loss: 0.4194\n",
      "Epoch 133/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4163 - val_loss: 0.4067\n",
      "Epoch 134/300\n",
      "21113/21113 [==============================] - 1s 30us/step - loss: 0.4162 - val_loss: 0.4104\n",
      "Epoch 135/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4164 - val_loss: 0.4083\n",
      "Epoch 136/300\n",
      "21113/21113 [==============================] - 1s 52us/step - loss: 0.4162 - val_loss: 0.4067\n",
      "Epoch 137/300\n",
      "21113/21113 [==============================] - 2s 71us/step - loss: 0.4158 - val_loss: 0.4049\n",
      "Epoch 138/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4163 - val_loss: 0.4050\n",
      "Epoch 139/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4162 - val_loss: 0.4034\n",
      "Epoch 140/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4163 - val_loss: 0.4036\n",
      "Epoch 141/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4160 - val_loss: 0.4133\n",
      "Epoch 142/300\n",
      "21113/21113 [==============================] - 1s 45us/step - loss: 0.4161 - val_loss: 0.4039\n",
      "Epoch 143/300\n",
      "21113/21113 [==============================] - 1s 46us/step - loss: 0.4160 - val_loss: 0.4034\n",
      "Epoch 144/300\n",
      "21113/21113 [==============================] - 1s 32us/step - loss: 0.4161 - val_loss: 0.4037\n",
      "Epoch 145/300\n",
      "21113/21113 [==============================] - 1s 31us/step - loss: 0.4158 - val_loss: 0.4056\n",
      "Epoch 146/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4161 - val_loss: 0.4043\n",
      "Epoch 147/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4159 - val_loss: 0.4184\n",
      "Epoch 148/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4159 - val_loss: 0.4037\n",
      "Epoch 149/300\n",
      "21113/21113 [==============================] - 1s 39us/step - loss: 0.4158 - val_loss: 0.4089\n",
      "Epoch 150/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4158 - val_loss: 0.4041\n",
      "Epoch 151/300\n",
      "21113/21113 [==============================] - 1s 39us/step - loss: 0.4158 - val_loss: 0.4033\n",
      "Epoch 152/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4155 - val_loss: 0.4126\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4160 - val_loss: 0.4055\n",
      "Epoch 154/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4157 - val_loss: 0.4162\n",
      "Epoch 155/300\n",
      "21113/21113 [==============================] - 1s 30us/step - loss: 0.4159 - val_loss: 0.4031\n",
      "Epoch 156/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4157 - val_loss: 0.4033\n",
      "Epoch 157/300\n",
      "21113/21113 [==============================] - 1s 32us/step - loss: 0.4159 - val_loss: 0.4048\n",
      "Epoch 158/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4156 - val_loss: 0.4033\n",
      "Epoch 159/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4158 - val_loss: 0.4118\n",
      "Epoch 160/300\n",
      "21113/21113 [==============================] - 1s 41us/step - loss: 0.4155 - val_loss: 0.4036\n",
      "Epoch 161/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4156 - val_loss: 0.4085\n",
      "Epoch 162/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4155 - val_loss: 0.4089\n",
      "Epoch 163/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4155 - val_loss: 0.4055\n",
      "Epoch 164/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4153 - val_loss: 0.4039\n",
      "Epoch 165/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4157 - val_loss: 0.4057\n",
      "Epoch 166/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4156 - val_loss: 0.4030\n",
      "Epoch 167/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4152 - val_loss: 0.4030\n",
      "Epoch 168/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4154 - val_loss: 0.4029\n",
      "Epoch 169/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4156 - val_loss: 0.4038\n",
      "Epoch 170/300\n",
      "21113/21113 [==============================] - 1s 32us/step - loss: 0.4153 - val_loss: 0.4030\n",
      "Epoch 171/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4154 - val_loss: 0.4031\n",
      "Epoch 172/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4154 - val_loss: 0.4055\n",
      "Epoch 173/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4156 - val_loss: 0.4031\n",
      "Epoch 174/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4152 - val_loss: 0.4085\n",
      "Epoch 175/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4151 - val_loss: 0.4035\n",
      "Epoch 176/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4156 - val_loss: 0.4069\n",
      "Epoch 177/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4150 - val_loss: 0.4037\n",
      "Epoch 178/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4154 - val_loss: 0.4030\n",
      "Epoch 179/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4155 - val_loss: 0.4035\n",
      "Epoch 180/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4150 - val_loss: 0.4028\n",
      "Epoch 181/300\n",
      "21113/21113 [==============================] - 1s 32us/step - loss: 0.4146 - val_loss: 0.4027\n",
      "Epoch 182/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4153 - val_loss: 0.4059\n",
      "Epoch 183/300\n",
      "21113/21113 [==============================] - 1s 26us/step - loss: 0.4152 - val_loss: 0.4040\n",
      "Epoch 184/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4150 - val_loss: 0.4056\n",
      "Epoch 185/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4153 - val_loss: 0.4029\n",
      "Epoch 186/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4153 - val_loss: 0.4074\n",
      "Epoch 187/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4150 - val_loss: 0.4041\n",
      "Epoch 188/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4154 - val_loss: 0.4031\n",
      "Epoch 189/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4153 - val_loss: 0.4027\n",
      "Epoch 190/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4150 - val_loss: 0.4035\n",
      "Epoch 191/300\n",
      "21113/21113 [==============================] - 1s 41us/step - loss: 0.4153 - val_loss: 0.4037\n",
      "Epoch 192/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4151 - val_loss: 0.4072\n",
      "Epoch 193/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4149 - val_loss: 0.4071\n",
      "Epoch 194/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4151 - val_loss: 0.4024\n",
      "Epoch 195/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4154 - val_loss: 0.4027\n",
      "Epoch 196/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4153 - val_loss: 0.4031\n",
      "Epoch 197/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4153 - val_loss: 0.4037\n",
      "Epoch 198/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4154 - val_loss: 0.4034\n",
      "Epoch 199/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4152 - val_loss: 0.4047\n",
      "Epoch 200/300\n",
      "21113/21113 [==============================] - 1s 46us/step - loss: 0.4150 - val_loss: 0.4052\n",
      "Epoch 201/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4151 - val_loss: 0.4037\n",
      "Epoch 202/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4154 - val_loss: 0.4028\n",
      "Epoch 203/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4151 - val_loss: 0.4042\n",
      "Epoch 204/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4150 - val_loss: 0.4076\n",
      "Epoch 205/300\n",
      "21113/21113 [==============================] - 1s 36us/step - loss: 0.4149 - val_loss: 0.4026\n",
      "Epoch 206/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4154 - val_loss: 0.4048\n",
      "Epoch 207/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4149 - val_loss: 0.4040\n",
      "Epoch 208/300\n",
      "21113/21113 [==============================] - 1s 42us/step - loss: 0.4151 - val_loss: 0.4037\n",
      "Epoch 209/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4151 - val_loss: 0.4042\n",
      "Epoch 210/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4152 - val_loss: 0.4036\n",
      "Epoch 211/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4150 - val_loss: 0.4094\n",
      "Epoch 212/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4150 - val_loss: 0.4101\n",
      "Epoch 213/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4149 - val_loss: 0.4026\n",
      "Epoch 214/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4150 - val_loss: 0.4118\n",
      "Epoch 215/300\n",
      "21113/21113 [==============================] - 1s 26us/step - loss: 0.4148 - val_loss: 0.4044\n",
      "Epoch 216/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4149 - val_loss: 0.4031\n",
      "Epoch 217/300\n",
      "21113/21113 [==============================] - 1s 26us/step - loss: 0.4150 - val_loss: 0.4070\n",
      "Epoch 218/300\n",
      "21113/21113 [==============================] - 1s 39us/step - loss: 0.4147 - val_loss: 0.4045\n",
      "Epoch 219/300\n",
      "21113/21113 [==============================] - 1s 42us/step - loss: 0.4150 - val_loss: 0.4045\n",
      "Epoch 220/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4149 - val_loss: 0.4056\n",
      "Epoch 221/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4151 - val_loss: 0.4051\n",
      "Epoch 222/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4149 - val_loss: 0.4024\n",
      "Epoch 223/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4149 - val_loss: 0.4033\n",
      "Epoch 224/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4148 - val_loss: 0.4030\n",
      "Epoch 225/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4150 - val_loss: 0.4025\n",
      "Epoch 226/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4148 - val_loss: 0.4125\n",
      "Epoch 227/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4149 - val_loss: 0.4146\n",
      "Epoch 228/300\n",
      "21113/21113 [==============================] - 1s 32us/step - loss: 0.4149 - val_loss: 0.4045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4150 - val_loss: 0.4041\n",
      "Epoch 230/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4151 - val_loss: 0.4029\n",
      "Epoch 231/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4149 - val_loss: 0.4032\n",
      "Epoch 232/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4148 - val_loss: 0.4043\n",
      "Epoch 233/300\n",
      "21113/21113 [==============================] - 1s 31us/step - loss: 0.4149 - val_loss: 0.4109\n",
      "Epoch 234/300\n",
      "21113/21113 [==============================] - 1s 51us/step - loss: 0.4150 - val_loss: 0.4030\n",
      "Epoch 235/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4149 - val_loss: 0.4024\n",
      "Epoch 236/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4148 - val_loss: 0.4081\n",
      "Epoch 237/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4150 - val_loss: 0.4034\n",
      "Epoch 238/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4152 - val_loss: 0.4048\n",
      "Epoch 239/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4150 - val_loss: 0.4025\n",
      "Epoch 240/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4150 - val_loss: 0.4026\n",
      "Epoch 241/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4149 - val_loss: 0.4034\n",
      "Epoch 242/300\n",
      "21113/21113 [==============================] - 1s 32us/step - loss: 0.4144 - val_loss: 0.4027\n",
      "Epoch 243/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4146 - val_loss: 0.4023\n",
      "Epoch 244/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4147 - val_loss: 0.4026\n",
      "Epoch 245/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4147 - val_loss: 0.4024\n",
      "Epoch 246/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4147 - val_loss: 0.4029\n",
      "Epoch 247/300\n",
      "21113/21113 [==============================] - 1s 30us/step - loss: 0.4146 - val_loss: 0.4024\n",
      "Epoch 248/300\n",
      "21113/21113 [==============================] - 1s 38us/step - loss: 0.4142 - val_loss: 0.4068\n",
      "Epoch 249/300\n",
      "21113/21113 [==============================] - 1s 34us/step - loss: 0.4147 - val_loss: 0.4035\n",
      "Epoch 250/300\n",
      "21113/21113 [==============================] - 1s 26us/step - loss: 0.4148 - val_loss: 0.4031\n",
      "Epoch 251/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4148 - val_loss: 0.4041\n",
      "Epoch 252/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4149 - val_loss: 0.4032\n",
      "Epoch 253/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4149 - val_loss: 0.4052\n",
      "Epoch 254/300\n",
      "21113/21113 [==============================] - 1s 33us/step - loss: 0.4148 - val_loss: 0.4023\n",
      "Epoch 255/300\n",
      "21113/21113 [==============================] - 1s 46us/step - loss: 0.4149 - val_loss: 0.4025\n",
      "Epoch 256/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4148 - val_loss: 0.4048\n",
      "Epoch 257/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4147 - val_loss: 0.4027\n",
      "Epoch 258/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4149 - val_loss: 0.4034\n",
      "Epoch 259/300\n",
      "21113/21113 [==============================] - 1s 27us/step - loss: 0.4150 - val_loss: 0.4030\n",
      "Epoch 260/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4151 - val_loss: 0.4025\n",
      "Epoch 261/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4152 - val_loss: 0.4040\n",
      "Epoch 262/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4149 - val_loss: 0.4027\n",
      "Epoch 263/300\n",
      "21113/21113 [==============================] - 1s 29us/step - loss: 0.4148 - val_loss: 0.4037\n",
      "Epoch 264/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4150 - val_loss: 0.4024\n",
      "Epoch 265/300\n",
      "21113/21113 [==============================] - 1s 32us/step - loss: 0.4149 - val_loss: 0.4047\n",
      "Epoch 266/300\n",
      "21113/21113 [==============================] - 1s 30us/step - loss: 0.4149 - val_loss: 0.4081\n",
      "Epoch 267/300\n",
      "21113/21113 [==============================] - 2s 75us/step - loss: 0.4149 - val_loss: 0.4043\n",
      "Epoch 268/300\n",
      "21113/21113 [==============================] - 1s 46us/step - loss: 0.4149 - val_loss: 0.4102\n",
      "Epoch 269/300\n",
      "21113/21113 [==============================] - 1s 30us/step - loss: 0.4146 - val_loss: 0.4024\n",
      "Epoch 270/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4147 - val_loss: 0.4047\n",
      "Epoch 271/300\n",
      "21113/21113 [==============================] - 1s 43us/step - loss: 0.4147 - val_loss: 0.4025\n",
      "Epoch 272/300\n",
      "21113/21113 [==============================] - 1s 32us/step - loss: 0.4149 - val_loss: 0.4082\n",
      "Epoch 273/300\n",
      "21113/21113 [==============================] - 1s 30us/step - loss: 0.4146 - val_loss: 0.4072\n",
      "Epoch 274/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4146 - val_loss: 0.4064\n",
      "Epoch 275/300\n",
      "21113/21113 [==============================] - 1s 30us/step - loss: 0.4147 - val_loss: 0.4023\n",
      "Epoch 276/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4147 - val_loss: 0.4046\n",
      "Epoch 277/300\n",
      "21113/21113 [==============================] - 1s 49us/step - loss: 0.4147 - val_loss: 0.4026\n",
      "Epoch 278/300\n",
      "21113/21113 [==============================] - 1s 52us/step - loss: 0.4146 - val_loss: 0.4033\n",
      "Epoch 279/300\n",
      "21113/21113 [==============================] - 1s 41us/step - loss: 0.4148 - val_loss: 0.4038\n",
      "Epoch 280/300\n",
      "21113/21113 [==============================] - 1s 64us/step - loss: 0.4146 - val_loss: 0.4055\n",
      "Epoch 281/300\n",
      "21113/21113 [==============================] - 1s 35us/step - loss: 0.4149 - val_loss: 0.4034\n",
      "Epoch 282/300\n",
      "21113/21113 [==============================] - 1s 28us/step - loss: 0.4148 - val_loss: 0.4027\n",
      "Epoch 283/300\n",
      "21113/21113 [==============================] - 1s 30us/step - loss: 0.4147 - val_loss: 0.4029\n",
      "Epoch 284/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4146 - val_loss: 0.4026\n",
      "Epoch 285/300\n",
      "21113/21113 [==============================] - 1s 37us/step - loss: 0.4144 - val_loss: 0.4103\n",
      "Epoch 286/300\n",
      "21113/21113 [==============================] - 1s 58us/step - loss: 0.4147 - val_loss: 0.4024\n",
      "Epoch 287/300\n",
      "21113/21113 [==============================] - 2s 82us/step - loss: 0.4147 - val_loss: 0.4034\n",
      "Epoch 288/300\n",
      "21113/21113 [==============================] - 2s 82us/step - loss: 0.4149 - val_loss: 0.4026\n",
      "Epoch 289/300\n",
      "21113/21113 [==============================] - 1s 70us/step - loss: 0.4149 - val_loss: 0.4039\n",
      "Epoch 290/300\n",
      "21113/21113 [==============================] - 2s 81us/step - loss: 0.4147 - val_loss: 0.4043\n",
      "Epoch 291/300\n",
      "21113/21113 [==============================] - 1s 56us/step - loss: 0.4144 - val_loss: 0.4026\n",
      "Epoch 292/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4150 - val_loss: 0.4024\n",
      "Epoch 293/300\n",
      "21113/21113 [==============================] - 1s 49us/step - loss: 0.4147 - val_loss: 0.4037\n",
      "Epoch 294/300\n",
      "21113/21113 [==============================] - 1s 47us/step - loss: 0.4148 - val_loss: 0.4027\n",
      "Epoch 295/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4151 - val_loss: 0.4067\n",
      "Epoch 296/300\n",
      "21113/21113 [==============================] - 1s 40us/step - loss: 0.4150 - val_loss: 0.4030\n",
      "Epoch 297/300\n",
      "21113/21113 [==============================] - 1s 59us/step - loss: 0.4146 - val_loss: 0.4042\n",
      "Epoch 298/300\n",
      "21113/21113 [==============================] - 1s 49us/step - loss: 0.4148 - val_loss: 0.4024\n",
      "Epoch 299/300\n",
      "21113/21113 [==============================] - 1s 53us/step - loss: 0.4146 - val_loss: 0.4052\n",
      "Epoch 300/300\n",
      "21113/21113 [==============================] - 1s 56us/step - loss: 0.4147 - val_loss: 0.4025\n",
      "9049/9049 [==============================] - 0s 18us/step\n",
      "0.40245408195529225\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "#Logistic regression algorithm Using Keras start\n",
    "\n",
    "#Instatiating Training and evaluating the model start\n",
    "\n",
    "# instantiate learning model\n",
    "rgmodel = Sequential()\n",
    "rgmodel.add(Dense(1, activation='sigmoid', input_dim=13))\n",
    "rgmodel.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "\n",
    "# fitting the model\n",
    "rgmodel.fit(X_train, y_train, epochs=300, validation_data=(X_test, y_test))\n",
    "\n",
    "# evaluate accuracy\n",
    "print(rgmodel.evaluate(X_test, y_test, batch_size=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21113/21113 [==============================] - 319s 15ms/step - loss: 0.5664 - acc: 0.7471\n",
      "Epoch 2/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.4581 - acc: 0.7471\n",
      "Epoch 3/50\n",
      "21113/21113 [==============================] - 0s 21us/step - loss: 0.4207 - acc: 0.7954\n",
      "Epoch 4/50\n",
      "21113/21113 [==============================] - 0s 16us/step - loss: 0.3953 - acc: 0.8115\n",
      "Epoch 5/50\n",
      "21113/21113 [==============================] - 0s 18us/step - loss: 0.3833 - acc: 0.8156\n",
      "Epoch 6/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3752 - acc: 0.8205\n",
      "Epoch 7/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3740 - acc: 0.8193\n",
      "Epoch 8/50\n",
      "21113/21113 [==============================] - 0s 18us/step - loss: 0.3698 - acc: 0.8217\n",
      "Epoch 9/50\n",
      "21113/21113 [==============================] - 0s 19us/step - loss: 0.3674 - acc: 0.8244\n",
      "Epoch 10/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3688 - acc: 0.8223\n",
      "Epoch 11/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3647 - acc: 0.8248\n",
      "Epoch 12/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3639 - acc: 0.8258\n",
      "Epoch 13/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3624 - acc: 0.8262\n",
      "Epoch 14/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3606 - acc: 0.8260\n",
      "Epoch 15/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3635 - acc: 0.8237\n",
      "Epoch 16/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3616 - acc: 0.8272\n",
      "Epoch 17/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3626 - acc: 0.8254\n",
      "Epoch 18/50\n",
      "21113/21113 [==============================] - 0s 17us/step - loss: 0.3610 - acc: 0.8268\n",
      "Epoch 19/50\n",
      "21113/21113 [==============================] - 0s 16us/step - loss: 0.3613 - acc: 0.8247\n",
      "Epoch 20/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3586 - acc: 0.8271\n",
      "Epoch 21/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3599 - acc: 0.8276\n",
      "Epoch 22/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3581 - acc: 0.8288\n",
      "Epoch 23/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3589 - acc: 0.8266\n",
      "Epoch 24/50\n",
      "21113/21113 [==============================] - 0s 16us/step - loss: 0.3576 - acc: 0.8284\n",
      "Epoch 25/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3585 - acc: 0.8266\n",
      "Epoch 26/50\n",
      "21113/21113 [==============================] - 0s 18us/step - loss: 0.3584 - acc: 0.8275\n",
      "Epoch 27/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3575 - acc: 0.8274\n",
      "Epoch 28/50\n",
      "21113/21113 [==============================] - 0s 17us/step - loss: 0.3576 - acc: 0.8301\n",
      "Epoch 29/50\n",
      "21113/21113 [==============================] - 0s 19us/step - loss: 0.3571 - acc: 0.8278\n",
      "Epoch 30/50\n",
      "21113/21113 [==============================] - 0s 19us/step - loss: 0.3571 - acc: 0.8275\n",
      "Epoch 31/50\n",
      "21113/21113 [==============================] - 0s 19us/step - loss: 0.3570 - acc: 0.8295\n",
      "Epoch 32/50\n",
      "21113/21113 [==============================] - 0s 18us/step - loss: 0.3570 - acc: 0.8289\n",
      "Epoch 33/50\n",
      "21113/21113 [==============================] - 0s 18us/step - loss: 0.3560 - acc: 0.8272\n",
      "Epoch 34/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3560 - acc: 0.8305\n",
      "Epoch 35/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3571 - acc: 0.8275\n",
      "Epoch 36/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3563 - acc: 0.8305\n",
      "Epoch 37/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3562 - acc: 0.8299\n",
      "Epoch 38/50\n",
      "21113/21113 [==============================] - 0s 20us/step - loss: 0.3567 - acc: 0.8281\n",
      "Epoch 39/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3558 - acc: 0.8299\n",
      "Epoch 40/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3566 - acc: 0.8283\n",
      "Epoch 41/50\n",
      "21113/21113 [==============================] - 0s 16us/step - loss: 0.3553 - acc: 0.8324\n",
      "Epoch 42/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3562 - acc: 0.8296\n",
      "Epoch 43/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3572 - acc: 0.8294\n",
      "Epoch 44/50\n",
      "21113/21113 [==============================] - 0s 16us/step - loss: 0.3535 - acc: 0.8311\n",
      "Epoch 45/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3547 - acc: 0.8306\n",
      "Epoch 46/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3540 - acc: 0.8301\n",
      "Epoch 47/50\n",
      "21113/21113 [==============================] - 0s 16us/step - loss: 0.3565 - acc: 0.8287\n",
      "Epoch 48/50\n",
      "21113/21113 [==============================] - 0s 14us/step - loss: 0.3556 - acc: 0.8304\n",
      "Epoch 49/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3554 - acc: 0.8312\n",
      "Epoch 50/50\n",
      "21113/21113 [==============================] - 0s 15us/step - loss: 0.3546 - acc: 0.8307\n",
      "[[6044  836]\n",
      " [ 714 1455]]\n",
      "0.8287103547353298\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "#Neural Network algorithm Using Keras start\n",
    "\n",
    "# instantiate learning model\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer aand the first hidden layer\n",
    "classifier.add(Dense(activation = \"relu\", input_dim = 13, units = 20, kernel_initializer=\"uniform\"))\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(activation = \"relu\",units = 20, kernel_initializer=\"uniform\"))\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(activation = \"relu\",units = 20, kernel_initializer=\"uniform\"))\n",
    "# Adding the fourth hidden layer\n",
    "classifier.add(Dense(activation = \"relu\",units = 20, kernel_initializer=\"uniform\"))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))\n",
    "# Compiling Neural Network\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# fitting the model\n",
    "classifier.fit(X_train, y_train, batch_size = 100, epochs = 50)\n",
    "\n",
    "# predict the response\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# evaluate accuracy with confusionmatrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Nural Network algorithm Using keras end\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
